{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RAG FAQ-app\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Load the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders.csv_loader import CSVLoader\n",
    "loader = CSVLoader('dockuno.csv')\n",
    "dataset = loader.load()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Load embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "# myembedmodels = OpenAIEmbeddings(openai_api_key=\"\")\n",
    "\n",
    "from langchain_community.embeddings import OllamaEmbeddings\n",
    "myembedmodels = OllamaEmbeddings(model=\"all-minilm\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: store embeddings into Vector Database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install -qU langchain-community faiss-cpu\n",
    "from langchain.vectorstores import FAISS\n",
    "db = FAISS.from_documents( documents=dataset , embedding=myembedmodels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# db.similarity_search(\"what is the fees in dollars?\")\n",
    "def retrieve_data(query):\n",
    "    similar_response = db.similarity_search(query)\n",
    "    ret_data = [ doc.page_content for doc in similar_response]\n",
    "    return ret_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Prepare template prompt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "dockuno_template = \"\"\"\n",
    "You are a world class business development representative for Dockuno program at eduLearn.ai .\n",
    "I will share a prospect's message with you and you will give me the best answer that I should send to this prospect based on past best practices, and you will follow ALL of the rules below:\n",
    "1/ Response should be very similar or even identical to the past best practies, in terms of length, ton of voice, logical arguments and other details\n",
    "2/ If the best practice are irrelevant, then try to mimic the style of the best practice to prospect's message\n",
    "3/ Keep the response short and crisp and to the point\n",
    "\n",
    "Below is a message I received from the prospect:\n",
    "{message}\n",
    "\n",
    "Here is a list of best practies of how we normally respond to prospect in similar scenarios:\n",
    "{best_practice}\n",
    "\n",
    "Please write the best response that I should send to this prospect:\n",
    "\"\"\"\n",
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "myprompt = PromptTemplate(template=dockuno_template, input_variables=[\"message\", \"best_practice\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 5 : prepare llm model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import ollama\n",
    "myllm = ollama.ChatOllama(model=\"tinyllama\", temperature=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### prepare chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import LLMChain\n",
    "\n",
    "my_chain = LLMChain(llm=myllm , prompt=myprompt)\n",
    "best_practice = retrieve_data(\"what is the fees in dollars?\")\n",
    "response = my_chain.run(message=\"I am saurabh, what is the fees of dockuno in dollar\", best_practice = best_practice)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dear Saurabh,\n",
      "\n",
      "Thank you for reaching out to us regarding your interest in our Dockuno program. We appreciate your inquiry and would like to provide you with some information about our course fee and pricing structure.\n",
      "\n",
      "Our course fee is based on the selected package, which includes the duration of the course, the number of days, and the level of instruction. The packages are as follows:\n",
      "\n",
      "- 1 Day Intensive Course (3 Days): 4000 INR\n",
      "- Self-Paced Learners (3 Days): 2500 INR\n",
      "- Live Q&A Sessions (Periodic): 2500 INR\n",
      "\n",
      "We understand that time is valuable, and we strive to provide you with the best possible learning experience. Our courses are designed to be self-paced, allowing learners to complete them at their own convenience. We also offer live Q&A sessions where you can ask questions directly to our instructors.\n",
      "\n",
      "We value your time and would like to assure you that we take your needs and requirements seriously. Our team of experts is dedicated to providing you with the best possible learning experience, and we are committed to ensuring that you receive the most out of your investment in our Dockuno program.\n",
      "\n",
      "If you have any further questions or concerns, please do not hesitate to contact us at [insert contact information]. We look forward to hearing from you soon!\n",
      "\n",
      "Best regards,\n",
      "\n",
      "[Your Name]\n",
      "\n",
      "[Your Title]\n",
      "\n",
      "[Company Name]\n"
     ]
    }
   ],
   "source": [
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
